{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Introduction \n",
        "\n",
        "The aim of this lab is to get familiar with **classification problems** using **Multinomial Logistic Regression**, **Decision Trees** and **Naive Bayes**. \n",
        "\n",
        "For this lab, we will be using the [iris dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset) and the [forest covertypes](https://scikit-learn.org/stable/datasets/real_world.html#forest-covertypes) dataset."
      ],
      "metadata": {
        "id": "NXAjz472vqN6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw-JDM6Kvksm"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import linear_model\n",
        "from sklearn import tree\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from imblearn import over_sampling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from IPython import display\n",
        "\n",
        "import typing\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "print(iris.DESCR)"
      ],
      "metadata": {
        "id": "hMaoo4y1xZFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will again be splitting the data into train and test sets and this time, will use sklearn `StandardScaler` to scale the attributes."
      ],
      "metadata": {
        "id": "K9pCLve8xjwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.data\n",
        "Y = iris.target\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        "    )\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "WHlGiQF5xq07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Multinomial Regression\n",
        "In the previous lab, we implemented a logistic regression classifier ourselves. Here, we will instead import it from the python's scikit-learn library. As there are several parameters that can be passed, please read and understand the documentation of sklearn for [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Adjust the code below to use L2 regularization, the appropriare solver and multi_class options."
      ],
      "metadata": {
        "id": "OqDL4T5My4ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here\n",
        "# log_reg_classifier = linear_model.LogisticRegression(C=1e5, solver='???', multi_class='???', penalty='???')\n",
        "# log_reg_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "kGyWlzlO04DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the accuracy of the classifier on the test set? How does it compare to last weeks 1 vs all example?"
      ],
      "metadata": {
        "id": "njdFoCBl38W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "-m9gkU3e4CbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the iris example is relatively simple, it achieves high accuracy easily. We will be using the Forest Covertype dataset for a more complex example. Please read the dataset documentation for details on the attributes and the dataset in general."
      ],
      "metadata": {
        "id": "3FUfQ0g66icm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = datasets.fetch_covtype()\n",
        "print(forest.DESCR)"
      ],
      "metadata": {
        "id": "n4PbtLzP7BW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = forest.data\n",
        "Y = forest.target\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    X,\n",
        "    Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        "    )\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# X_train[:2]"
      ],
      "metadata": {
        "id": "cOjmIebf7QIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a classifier on the forest train data and use the test set to estimate the accuracy score."
      ],
      "metadata": {
        "id": "USItloJY8xyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "w7tYOsB588gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) visualisation of the classifier's performance on the test set. what do you observe? Why do you think this is the case?"
      ],
      "metadata": {
        "id": "Rx02G0KJ9WhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "_JztexyR9VSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Decision Trees\n",
        "\n",
        "Decision Trees are a type of Supervised Machine Learning where the data is continuously split according to a certain learned parameter. The trees are composed by two main entities, decision nodes and leaf nodes, where the latter is the final outcome.\n",
        "\n",
        "Using the sklearn [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision+tree), train a classifier on the forest train set, calculate the overall accuracy and plot the confusion matrix of the classifier. How does this compare to the Multinomial Logistic Regression?\n",
        "\n",
        "Use Entropy as a measure for information gain."
      ],
      "metadata": {
        "id": "WWwheIhU_VqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "5gNZtIf2A58k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Naive Bayes\n",
        "\n",
        "As the attributes of the dataset are scaled to continuous rela values, we will use a Gaussian Naive Bayes model. \n",
        "\n",
        "Using the [`GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html?highlight=naive+bayes) implementation for sklearn train a classifier on the forest train set, calculate the overall accuracy and plot the confusion matrix of the classifier. How does this compare to the previous two algorithms?\n",
        "\n",
        "Tune the hyper-parameter var-smoothing of the classifier for a fairer comparisson."
      ],
      "metadata": {
        "id": "UKvLyyFPB67r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "KfTxZTz6DQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Imbalance\n",
        "You will notice that contrary to the iris dataset, the forest dataset is imbalanced, this means that not all classes have an equal number of samples. This can lead to over-fitting as it can encourage the classifier to only predict the dominant class. Some algorithms are more prone to this than others, we see for example that the decision tree achieves high accuracy without adjusting while Multinomial regression achieves high accuracy on the dominant classes but not great otherwise.\n",
        "\n",
        "`LogisticRegression` has a parameter for class_weight, let's set this to balanced and retrain the classifier. Does the performance of the classifier improve?"
      ],
      "metadata": {
        "id": "gRyQASlXHonm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "C_gPH3WTI3wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another solution, is to implement a sampling strategy. Various methods for over-sampling and under-sampling are available, we will use Synthetic Minority Over-sampling Technique ([SMOTE](https://doi.org/10.1613/jair.953)) as implemented in [imblearn](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html).\n",
        "\n",
        "Retrain the logistic regression classifier using the resampled x, y data (this will take a while now) and evaluate on the original test set. \n",
        "\n",
        "Compare the metrics to previous implementations."
      ],
      "metadata": {
        "id": "XnPL16omJf0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = over_sampling.SMOTE(sampling_strategy='not majority', random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "print(len(X_resampled)) # notice the difference in the number of samples"
      ],
      "metadata": {
        "id": "f_Bp_-c3KK70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "7nwoVXj7K5OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if you retrain the NB classifier with the resampled data? Why is this happening?"
      ],
      "metadata": {
        "id": "agAAveGzThUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "ZVsU5N_PTbEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}