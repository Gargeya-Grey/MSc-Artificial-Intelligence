{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "mQslhrvBbZEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgSL39WPixib"
      },
      "outputs": [],
      "source": [
        "from torchtext.models import T5Transform\n",
        "\n",
        "padding_idx = 0\n",
        "eos_idx = 1\n",
        "max_seq_len = 512\n",
        "t5_sp_model_path = \"https://download.pytorch.org/models/text/t5_tokenizer_base.model\"\n",
        "\n",
        "transform = T5Transform(\n",
        "    sp_model_path=t5_sp_model_path,\n",
        "    max_seq_len=max_seq_len,\n",
        "    eos_idx=eos_idx,\n",
        "    padding_idx=padding_idx,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvtA4LE8ixic"
      },
      "source": [
        "Alternatively, we can also use the transform shipped with the pre-trained models that does all of the above out-of-the-box\n",
        "\n",
        "```\n",
        "from torchtext.models import T5_BASE_GENERATION\n",
        "transform = T5_BASE_GENERATION.transform()\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxLrnx-Lixic"
      },
      "source": [
        "## Model Preparation\n",
        "\n",
        "torchtext provides SOTA pre-trained models that can be used directly for NLP tasks or fine-tuned on downstream tasks. Below\n",
        "we use the pre-trained T5 model with standard base configuration to perform text summarization, sentiment classification, and\n",
        "translation. For additional details on available pre-trained models, see [the torchtext documentation](https://pytorch.org/text/main/models.html)_\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3DST9oJixic"
      },
      "outputs": [],
      "source": [
        "from torchtext.models import T5_BASE_GENERATION\n",
        "\n",
        "\n",
        "t5_base = T5_BASE_GENERATION\n",
        "transform = t5_base.transform()\n",
        "model = t5_base.get_model()\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPfiWanixic"
      },
      "source": [
        "## GenerationUtils\n",
        "\n",
        "We can use torchtext's ``GenerationUtils`` to produce an output sequence based on the input sequence provided. This calls on the\n",
        "model's encoder and decoder, and iteratively expands the decoded sequences until the end-of-sequence token is generated\n",
        "for all sequences in the batch. The ``generate`` method shown below uses greedy search to generate the sequences. Beam search and\n",
        "other decoding strategies are also supported.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih6KvFcwixid"
      },
      "outputs": [],
      "source": [
        "from torchtext.prototype.generate import GenerationUtils\n",
        "from functools import partial\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "sequence_generator = GenerationUtils(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9_fH0Obixid"
      },
      "source": [
        "Finally, we can also load the Multi30k dataset to demonstrate English to German translation using the T5 model.\n",
        "This dataset has a train, validation, and test split. Below we demo on the test split.\n",
        "\n",
        "The T5 model uses the prefix \"translate English to German\" for this task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK8cuwpvixie"
      },
      "source": [
        "## Generate Translations\n",
        "\n",
        "Finally, we can also use the model to generate English to German translations on the first batch of examples from the Multi30k\n",
        "test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybki6lIkixie"
      },
      "source": [
        "## Translation Output\n",
        "\n",
        "::\n",
        "\n",
        "   Example 1:\n",
        "\n",
        "   input_text: translate English to German: A man in an orange hat starring at something.\n",
        "\n",
        "   prediction: Ein Mann in einem orangen Hut, der an etwas schaut.\n",
        "\n",
        "   target: Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.\n",
        "\n",
        "\n",
        "   Example 2:\n",
        "\n",
        "   input_text: translate English to German: A Boston Terrier is running on lush green grass in front of a white fence.\n",
        "\n",
        "   prediction: Ein Boston Terrier läuft auf üppigem grünem Gras vor einem weißen Zaun.\n",
        "\n",
        "   target: Ein Boston Terrier läuft über saftig-grünes Gras vor einem weißen Zaun.\n",
        "\n",
        "\n",
        "   Example 3:\n",
        "\n",
        "   input_text: translate English to German: A girl in karate uniform breaking a stick with a front kick.\n",
        "\n",
        "   prediction: Ein Mädchen in Karate-Uniform bricht einen Stöck mit einem Frontkick.\n",
        "\n",
        "   target: Ein Mädchen in einem Karateanzug bricht ein Brett mit einem Tritt.\n",
        "\n",
        "\n",
        "   Example 4:\n",
        "\n",
        "   input_text: translate English to German: Five people wearing winter jackets and helmets stand in the snow, with snowmobiles in the background.\n",
        "\n",
        "   prediction: Fünf Menschen mit Winterjacken und Helmen stehen im Schnee, mit Schneemobilen im Hintergrund.\n",
        "\n",
        "   target: Fünf Leute in Winterjacken und mit Helmen stehen im Schnee mit Schneemobilen im Hintergrund.\n",
        "\n",
        "\n",
        "   Example 5:\n",
        "\n",
        "   input_text: translate English to German: People are fixing the roof of a house.\n",
        "\n",
        "   prediction: Die Leute fixieren das Dach eines Hauses.\n",
        "\n",
        "   target: Leute Reparieren das Dach eines Hauses.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu import corpus_bleu\n",
        "def bleu_score(li_abs_hyp, li_abs_ref):\n",
        "    \"\"\"\n",
        "    Computes the BLEU score\n",
        "    :param li_abs_hyp: list of hypothesis abstracts (token strings)\n",
        "    :param li_abs_ref: list of reference abstracts (token strings)\n",
        "    \"\"\"\n",
        "    bleu = corpus_bleu(li_abs_hyp, [li_abs_ref])\n",
        "\n",
        "    return bleu.score\n"
      ],
      "metadata": {
        "id": "xiG448DPZfUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv(\"test_2016_flickr.csv\", index_col=0)\n",
        "test_eng = list(map(lambda x: \"translate English to German: \"+x, test[\"to\"]))"
      ],
      "metadata": {
        "id": "KKrH3SJoJ6WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "id": "PbKK1QlcKowT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "hPP3aEh7axnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install accelerate\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\", device_map=\"auto\")\n",
        "\n",
        "output_text = []\n",
        "for input_text in test_eng:\n",
        "  input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
        "\n",
        "  outputs = model.generate(input_ids)\n",
        "  output_text.append(tokenizer.decode(outputs[0]))\n"
      ],
      "metadata": {
        "id": "-1QZKa17ULav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(map(lambda x: x.split(\"<pad> \")[1][:-4], output_text))"
      ],
      "metadata": {
        "id": "gtiUIxSFfhZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score(test[\"from\"].tolist(), output_text) #34.368"
      ],
      "metadata": {
        "id": "ggeZCgxBcU7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying the German to english"
      ],
      "metadata": {
        "id": "1JNoN_Xzs4XG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "3t_v3cEhtPb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-de-en\", device=\"cuda\")\n",
        "\n",
        "input_text = test[\"from\"].tolist()\n",
        "target = test[\"to\"].tolist()\n",
        "translated = translator(input_text)\n",
        "\n",
        "print(translated)\n",
        "output_text = list(map(lambda x: list(x.values())[0], translated))\n",
        "print(output_text)\n"
      ],
      "metadata": {
        "id": "V1v3mlLws7hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score(output_text, target) # 34.687"
      ],
      "metadata": {
        "id": "USN3-RW5ubIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}